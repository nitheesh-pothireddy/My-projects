{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49cc1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary python libraries and modules required to build the model(s)\n",
    "import pandas as pd\n",
    "import hashlib\n",
    "import numpy as np\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import hamming_loss\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e000fc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert hashkey string values present in the data into numerical values \n",
    "\n",
    "def hash_to_number(hash_key):\n",
    "    return hash(hash_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb20ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classifier \n",
    "RFclassifier = LabelPowerset(\n",
    "    classifier = RandomForestClassifier(),\n",
    "    require_dense = [False,True]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1464d94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Classifier\n",
    "DTclassifier = LabelPowerset(\n",
    "    classifier = DecisionTreeClassifier(),\n",
    "    require_dense = [False,True]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561b5a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Neural Network\n",
    "NNclassifier = MLPClassifier(max_iter=400)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a1f9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the train,test and training labels using pandas\n",
    "df1 = pd.read_csv(\"train.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2768a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"test.csv\",header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea55e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.read_csv(\"trainLabels.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ffb208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging train and training label \n",
    "merged_df = pd.merge(df1, df3, on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1186929e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# replacing columns with YES/NO data with 1/0 and empty values with -1\n",
    "merged_df.replace({'YES':1,'NO':0,np.nan:-1},inplace=True)\n",
    "    \n",
    "object_columns = merged_df.select_dtypes(include='object').columns\n",
    "\n",
    "# applying the hash function to the rows containing hash strings\n",
    "for column in object_columns:\n",
    "    merged_df[column] = merged_df[column].apply(hash_to_number)\n",
    "    \n",
    "X = merged_df\n",
    "y = merged_df\n",
    "    \n",
    "for column in merged_df.columns:\n",
    "    if column.startswith('y'):\n",
    "        X = X.drop(columns=column)\n",
    "    elif column.startswith('x'):\n",
    "        y = y.drop(columns=column)\n",
    "X = X.drop(columns='id')\n",
    "y = y.drop(columns='id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2095df29",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702c48bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "RFclassifier.fit(np.array(X_train), np.array(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef839511",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions1 = RFclassifier.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test,predictions1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1a805f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hamming_loss(y_test, predictions1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd3b8ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NNclassifier.fit(np.array(X_train), np.array(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935f9650",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions2 = NNclassifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8336ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test,predictions2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6328e5d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DTclassifier.fit(np.array(X_train), np.array(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1332206",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions3 = DTclassifier.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test,predictions3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7604a00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying preprocessing for test data\n",
    "merged_df2 = df2\n",
    "\n",
    "merged_df2.replace({'YES':1,'NO':0,np.nan:-1},inplace=True)\n",
    "    \n",
    "object_columns = merged_df2.select_dtypes(include='object').columns\n",
    "\n",
    "merged_df2 = merged_df2.drop(columns=0)\n",
    "\n",
    "\n",
    "for column in object_columns:\n",
    "    merged_df2[column] = merged_df2[column].apply(hash_to_number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b54a91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy of Random Forest Classifier ~82%, Accuracy of Neural Network ~25% (with high variance),Accuracy of Decision Tree Classifier ~72%\n",
    "# Hence Random Forest Classifier will be used with the entire training data to make prediction for the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68a45dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "RFclassifier.fit(np.array(X), np.array(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9c7b1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions4 = RFclassifier.predict(merged_df2)\n",
    "\n",
    "print(predictions4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d4dafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_matrix = predictions4.todense()\n",
    "\n",
    "# Creating a pandas DataFrame from the dense matrix\n",
    "final_pred = pd.DataFrame(dense_matrix)\n",
    "display(final_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e377622c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred['id'] = 1698001 + final_pred.index\n",
    "final_pred = final_pred[['id'] + [col for col in final_pred.columns if col != 'id']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc01acbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extracting the 'id' column\n",
    "id_col = final_pred['id']\n",
    "\n",
    "# Creating an empty DataFrame to store the transformed data\n",
    "transformed_df = pd.DataFrame(columns=['id_label', 'pred'])\n",
    "\n",
    "# Iterating over each row in the original DataFrame\n",
    "for index, row in final_pred.iterrows():\n",
    "    # Extracting the 'id' value for the current row\n",
    "    current_id = row['id']\n",
    "    \n",
    "    # Iterating over the remaining columns (y1, y2, y3, etc.)\n",
    "    for col in final_pred.columns[1:]:\n",
    "        # Generating the new 'col1' value by concatenating id and column name\n",
    "        col1_value = f\"{current_id}_y{col+1}\"\n",
    "        \n",
    "        # Getting the 'col2' value from the original DataFrame\n",
    "        col2_value = row[col]\n",
    "        \n",
    "        # Appending the new values to the transformed DataFrame\n",
    "        transformed_df = pd.concat([transformed_df, pd.DataFrame({'id_label': [col1_value], 'pred': [col2_value]})], ignore_index=True)\n",
    "\n",
    "# Displaying the transformed DataFrame\n",
    "print(transformed_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73694f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final Output file generated\n",
    "transformed_df.to_csv('NitheeshP-prediction-output.csv',index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83b0d43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e16a16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
